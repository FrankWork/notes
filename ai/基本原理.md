## 什么样的资料集不适合用深度学习?

1. 数据集太小，数据样本不足时，深度学习相对其它机器学习算法，没有明显优势。
2 .数据集没有局部相关特性，目前深度学习表现比较好的领域主要是图像／语音／自然语言处理等领域，这些领域的一个共性是局部相关性。

## 何为共线性, 跟过拟合有啥关联?

1. 多变量线性回归中，变量之间由于存在高度相关关系而使回归估计不准确。
2. 共线性会造成冗余，导致过拟合。
3. 解决方法：排除变量的相关性／加入权重正则

## 对所有优化问题来说, 有没有可能找到比現在已知算法更好的算法?

对于一个学习算法A，若它在某些问题上比学习算法 B更好，则必然存在一些问题，在那里B比A好
也就是说：对于所有问题，无论学习算法A多聪明，学习算法B多笨拙，它们的期望性能相同。
但是：没有免费午餐定力假设所有问题出现几率相同，实际应用中，不同的场景，会有不同的问题分布，所以，在优化算法时，针对具体问题进行分析，是算法优化的核心所在。

## 梯度消失问题

1. 前馈神经网络（包括全连接层、卷积层等）可以表示为 

$$F = f_{3} (f_{2} (f_{1} (xW_{1})W_{2})W_{3})$$

网络输出对$W_{1}$求偏导

$$ \frac{\partial F}{\partial W_{1}}= x*f'_{1}*W_{2}*f'_{2}*W_{3}*f'_{3} $$

这里$W_{1}W_{2}W_{3}$ 是相互独立的，一般不会有数值问题；主要问题在于激活函数的导数$f'$在饱和区接近于零，导致梯度消失。

2. 循环神经网络的状态循环部分可以表示为

$$ h_{3}=f_{3} (f_{2} (f_{1} (h_{0}W)W)W) $$

这里的问题不仅在于激活函数的导数，还有$W$在不同时刻是共享的，网络输出对$W$的偏导包含$W$的连乘项，（$W$值偏小或偏大）就会出现梯度消失或爆炸

## 广义线性模型是怎被应用在深度学习中?

深度学习从统计学角度，可以看做递归的广义线性模型。
广义线性模型相对于经典的线性模型(y=wx+b)，核心在于引入了连接函数g(.)，形式变为：y=g−1(wx+b)。
深度学习时递归的广义线性模型，神经元的激活函数，即为广义线性模型的链接函数。
逻辑回归（广义线性模型的一种）的Logistic函数即为神经元激活函数中的Sigmoid函数


## 矩阵行列式的物理意义

行列式就是矩阵对应的线性变换对空间的拉伸程度的度量，或者说物体经过变换前后的体积比

## 深层网络可以避开较差Local Optima


## 量化句子之间的相似度

- word2vec 向量相加，bag of words
- TF-IDF，余弦相似度
- SVD和LSI
- LDA


