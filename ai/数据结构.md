## 合并两颗平衡二叉树

1. 首先，将两棵树分别展开为有序链表，时间复杂度分别为O(m)和O(n)；中序遍历
2. 然后将两个有序链表合并，时间复杂度为O(m + n)；
3. 最后把一个有序链表转化为一个平衡二叉树，时间复杂度为O(m + n)。
   用数组的中间元素作为根建立二叉树，然后递归简历左子树，右子树

## 把16位进制的数转换成2进制的数

十六进制数中的每一位数转换为二进制数,每个数要分四位,不足四位的前面加零,将得出四位二进制数串连起来就是结果了

## 10进制2进制转化

1. 正数：将正的十进制数除以二，得到的商再除以二，依次类推知道商为零或一时为止，然后在旁边标出各步的余数，最后倒着写出来，高位补零
2. 负数：先是将对应的正整数转换成二进制后，对二进制取反，然后对结果再加一
3. 小数：对小数点以后的数乘以2，取结果的整数部分（不是1就是0），然后再用小数部分再乘以2，再取结果的整数部分……以此类推，直到小数部分为0或者位数已经够了就OK了。然后把取的整数部分按先后次序排列

## linux下如何把两个文件按照列合并

paste names numbers   将两个文件合并用tab键分隔开

## map-reduce的原理
映射，规约：这个任务首先要分解成许多子任务，然后这些小任务要在这些电脑上面去分配，然后这些电脑完成了任务之后反馈的结果还要汇总

## 链表逆转
- 迭代法：指针反转
- 递归法

## 遍历树

前序，中序，后序：递归，栈

## 40亿数据如何用2G内存排序

1Gb = (1024)^3B  ~= 10^9
40亿int=40x10^8x4B=16x10^9 =14.9Gb ~= 16Gb

- 用哈希分成1000个小文件,小文件排序
- 每个文件里面取第一个数字，组成 (数字, 文件号) 这样的组合加入到堆里
- 不断从堆顶拿元素出来，每拿出一个元素，把它的文件号读取出来，然后去对应的文件里，加一个元素进入堆


## 1亿的文本如何放在100台机器上两两做相似度计算

1. simhash
2. 分桶，桶之内的哈希值两两比较

## 100亿数字，怎么统计前100大的？海量数据的topk问题 

1. 分块处理，然后再合并起来。如果不分块，这中间存在大量的没有必要的比较
2. 对于每一块必须找出100个最大的数

## 有几个 G 的文本，每行记录了访问 ip 的 log ，如何快速统计 ip 出现次数最高的 10 个 ip，如果只用 linux 指令又该怎么解决；



## 如果有一个人注册一个qq，如何保证这个qq号码和之前已存在的qq号码不重复呢？

trie树


# 一个大文件A和一个小文件B，里面存的是单词，要求出在文件B中但不在文件A中的单词。然后大文件A是无法直接存到内存中的。

对文件A的词哈希分块，对文件B的词哈希分块，只比较相同哈希块中的单词