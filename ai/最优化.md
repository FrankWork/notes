# 常用的优化方法

1. 梯度下降法（Gradient Descent）
2. 牛顿法和拟牛顿法（Newton's method & Quasi-Newton Methods）
3. 共轭梯度法（Conjugate Gradient）
4. 启发式优化方法
5. 解决约束优化问题——拉格朗日乘数法

## 梯度下降法

当前位置负梯度方向作为搜索方向，因为该方向为当前位置的最快下降方向
1. 靠近极小值时收敛速度减慢
2. 直线搜索时可能会产生一些问题
3. 可能会“之字形”地下降

批量梯度下降---最小化所有训练样本的损失函数，使得最终求解的是全局的最优解，即求解的参数是使得风险函数最小，但是对于大规模样本问题效率低下。

随机梯度下降---最小化每条样本的损失函数，虽然不是每次迭代得到的损失函数都向着全局最优方向， 但是大的整体的方向是向全局最优解的，最终的结果往往是在全局最优解附近，适用于大规模训练样本情况。

## 牛顿法

- 使用函数$f(x)$的泰勒级数的前面几项来寻找方程$f(x) = 0$的根。
- 最大的特点就在于它的收敛速度很快，计算复杂
- 牛顿法是二阶收敛，梯度下降是一阶收敛，所以牛顿法就更快，切线法
- 拟牛顿法用正定矩阵来近似Hessian矩阵的逆，简化运算，割线

### 步骤

1. 选择一个接近函数$f(x)$零点的$x_{0}$，
2. 计算相应的$f(x_{0})$和导数$f'(x_{0})$,
3. 计算穿过点$(x_{0},  f(x_{0}))$ 并且斜率为$f'(x_{0})$的直线和x轴的交点的x'坐标，
4. 对x'用同样的方法进行迭代

#  共轭梯度法

- 求解无约束最优化问题
- 共轭梯度法的基本思想是把共轭性与梯度下降方法相结合，利用已知点处的梯度构造一组共轭方向，并沿这组方向进行搜素，求出目标函数的极小点。

# 启发式算法

## 遗传算法
1. 种群初始化：根据问题特性设计合适的初始化操作（初始化操作应尽量简单，时间复杂度不易过高）对种群中的N个个体进行初始化操作；
2. 个体评价：根据优化的目标函数计算种群中个体的适应值（fitness value）；
3. 迭代设置：设置种群最大迭代次数gmax，并令当前迭代次数g=1；
4. 个体选择：
  - 设计合适的选择算子来对种群P(g)个体进行选择，被选择的个体将进入交配池中组成父代种群FP(g)，用于交叉变换以产生新的个体。
  - 选择策略要基于个体适应值来进行，假如要优化的问题为最小化问题，那么具有较小适应值的个体被选择的概率相应应该大一些。常用的选择策略有轮盘赌选择，锦标赛选择等。
5. 交叉算子：根据交叉概率pm（预先指定，一般为0.9）来判断父代个体是否需要进行交叉操作。交叉算子要根据被优化问题的特性来设计，它是整个遗传算法的核心，它被设计的好坏将直接决定整个算法性能的优劣。
6. 变异算子：根据变异概率pc（预先指定，一般为0.1）来判断父代个体是否需要进行变异操作。变异算子的主要作用是保持种群的多样性，防止种群陷入局部最优，所以其一般被设计为一种随机变换。

## 模拟退火算法

模拟退火算法是受物理学领域启发而提出的一种优化算法。所谓的退火是指将合金加热后再慢慢冷却的过程。大量的原子因为受到激发而向周围跳跃，然后又逐渐稳定到一个低能阶的状态，所以这些原子能够找到一个低能阶的配置（configuration）。

退火算法以一个问题的随机解开始。它用一个变量来表示温度，这一温度开始时非常高，而后逐渐变低

# 拉格朗日乘数法

- 解决约束优化问题
- 基本思想就是通过引入拉格朗日乘子来将含有n个变量和k个约束条件的约束优化问题转化为含有（n+k）个变量的无约束优化问题
- 步骤
  1. 对n个变量分别求偏导对应了n个方程，
  2. 然后加上k个约束条件（对应k个拉格朗日乘子），一起构成包含了（n+k）变量的（n+k）个方程的方程组问题
  3. 这样就能根据求方程组的方法对其进行求解
