# 残差网络

- 残差可以突出微小的变化，对输出的变化更敏感
- 只单纯增加深度会导致网络退化，而不是过拟合，退化是指连训练集都拟合不好
- resnet最初的想法是在训练集上，深层网络不应该比浅层网络差，因为只需要深层网络多的那些层做恒等映射就简化为了浅层网络。所以从学习恒等映射这点出发，考虑到网络要学习一个F(x)=x的映射比学习F(x)=0的映射更难，所以可以把网络结构设计成H(x) = F(x) + x，这样就即完成了恒等映射的学习，又降低了学习难度
- H(x)=F(x)+x，而不是$\lambda x$，是因为梯度会有$\lambda$的连乘项，容易导致梯度消失或爆炸，变的和没有残差连接一样了
- 残差网络效果好，很大程度上依赖于残差连接回传的梯度缓解梯度消失等问题
- 残差连接可以让不同层次的特征组合在一起


# 增加维度
- zero padding
- 1x1卷积